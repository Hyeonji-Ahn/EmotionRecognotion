{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "DISC Program\n",
    "Written by: Tiffany Ahn, Shierly Xiong, Shi Fu\n",
    "Feat. CHAT GPT\n",
    "\n",
    "1. Edit mainDir to be the main folder with the video in.\n",
    "2. Edit the movFile path to be the file name of the video\n",
    "3. Change the File paths of the line that indicated by #CHANGE FILE PATH\n",
    "4. If needed, tune the eye size, fixed scale, and area of interest\n",
    "\n",
    "Running Order (just run the whole file. it should work.):\n",
    "    1. Video to Frames\n",
    "    2. Cropping it to rectangle\n",
    "    3. Cropping it to face\n",
    "    4. Cropping out eye\n",
    "    5. DISC Analysis\n",
    "    6. Read DISC file and draw map\n",
    "\n",
    "Also, run the graphing file after the whole process.\n",
    "***strain field NEEDS DEBUGGING\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "#import and file path setup\n",
    "#for all the files\n",
    "import os\n",
    "import cv2\n",
    "\n",
    "#for color Transform\n",
    "import numpy as np\n",
    "\n",
    "#for mainDISC\n",
    "from matplotlib import pyplot as plt\n",
    "from scipy import stats\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import glob\n",
    "import imp\n",
    "\n",
    "mainDir = r\"C:\\Users\\ahj28\\Desktop\\Garcia DISC Data\\Control - 2522\\weight\" #CHANGE FILE PATH\n",
    "MovFile = 'IMG_2522_edited.mp4' #CHANGE FILE PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#video to frames\n",
    "\n",
    "inDir_VTF = mainDir\n",
    "outDir_VTF = mainDir+\"/OriFrames\"\n",
    "\n",
    "if not os.path.exists(outDir_VTF):\n",
    "    os.makedirs(outDir_VTF)\n",
    "\n",
    "vc = cv2.VideoCapture(inDir_VTF + '/'+MovFile) # change the name of the video file\n",
    "c = 10\n",
    "\n",
    "if vc.isOpened():\n",
    "    rval, frame = vc.read()\n",
    "else:\n",
    "    rval = False\n",
    "    \n",
    "print(rval) # for checking if the file exists\n",
    "\n",
    "timeF = 30 #number of actual frames between two captured frames\n",
    "\n",
    "while rval:\n",
    "    \n",
    "    rval, frame = vc.read()\n",
    "    if c%timeF == 0:\n",
    "        cv2.imwrite(outDir_VTF + '/' + str(1100000+c) + r'.png', frame)\n",
    "        print('Read a new frame: ', c)\n",
    "    c += 1\n",
    "    cv2.waitKey(1)\n",
    "vc.release()\n",
    "\"\"\"\n",
    "# All the frames\n",
    "#Tiffany: I do not understand what is purpose of the code below\n",
    "\n",
    "# vidcap = cv2.VideoCapture('big_buck_bunny_720p_5mb.mp4')\n",
    "# success,image = vidcap.read()\n",
    "count = 0\n",
    "while rval:\n",
    "    rval, frame = vc.read()\n",
    "    if rval:\n",
    "        cv2.imwrite(outDir_VTF + '/Frames/'+'frame' + str(100000+count) +r'.jpg', frame)     # save frame as JPEG file      \n",
    "\n",
    "        print('Read a new frame: ', count)\n",
    "    count += 1\n",
    "    cv2.waitKey(1)\n",
    "print('done!')\n",
    "vc.release()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Crop in Square\n",
    "\n",
    "window_width = 800\n",
    "window_height = 600\n",
    "\n",
    "\n",
    "def draw_box(image):\n",
    "    # Display the image and allow the user to draw a box\n",
    "    clone = image.copy()\n",
    "    cv2.namedWindow(\"Draw Box\", cv2.WINDOW_NORMAL)\n",
    "    cv2.resizeWindow(\"Draw Box\", window_width, window_height)\n",
    "    cv2.imshow(\"Draw Box\", clone)\n",
    "\n",
    "    # Initialize variables for the box coordinates\n",
    "    box_start = None\n",
    "    box_end = None\n",
    "    drawing = False\n",
    "\n",
    "    def draw_rectangle(event, x, y, flags, param):\n",
    "        nonlocal box_start, box_end, drawing\n",
    "\n",
    "        # Handle mouse events\n",
    "        if event == cv2.EVENT_LBUTTONDOWN:\n",
    "            box_start = (x, y)\n",
    "            drawing = True\n",
    "\n",
    "        elif event == cv2.EVENT_LBUTTONUP:\n",
    "            box_end = (x, y)\n",
    "            drawing = False\n",
    "\n",
    "            # Draw the rectangle on the image\n",
    "            cv2.rectangle(clone, box_start, box_end, (0, 255, 0), 2)\n",
    "            cv2.imshow(\"Draw Box\", clone)\n",
    "\n",
    "    # Register the callback function for mouse events\n",
    "    cv2.setMouseCallback(\"Draw Box\", draw_rectangle)\n",
    "\n",
    "    # Wait for the user to draw the box and close the window\n",
    "    while True:\n",
    "        key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "        if key == ord(\"r\"):\n",
    "            # Reset the box if the 'r' key is pressed\n",
    "            clone = image.copy()\n",
    "            cv2.imshow(\"Draw Box\", clone)\n",
    "\n",
    "        elif key == ord(\"c\"):\n",
    "            # Close the window and proceed to crop the images if the 'c' key is pressed\n",
    "            break\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "    # Return the box coordinates\n",
    "    return box_start, box_end\n",
    "\n",
    "\n",
    "def crop_images(images, box_start, box_end):\n",
    "    cropped_images = []\n",
    "\n",
    "    # Crop each image based on the box coordinates\n",
    "    for image in images:\n",
    "        cropped_image = image[box_start[1]:box_end[1], box_start[0]:box_end[0]]\n",
    "\n",
    "        # Create a mask with the same size as the cropped image\n",
    "        mask = np.zeros(cropped_image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "        # Set the region outside the box to be transparent\n",
    "        cv2.rectangle(mask, (0, 0), (cropped_image.shape[1], cropped_image.shape[0]), (255,), -1)\n",
    "\n",
    "        # Set the cropped region to be opaque (non-transparent)\n",
    "        cv2.rectangle(mask, (box_start[0], box_start[1]), (box_end[0], box_end[1]), (0,), -1)\n",
    "\n",
    "        # Merge the cropped image with the transparent mask\n",
    "        cropped_image = cv2.merge((cropped_image, mask[:, :, np.newaxis]))\n",
    "\n",
    "        cropped_images.append(cropped_image)\n",
    "\n",
    "    return cropped_images\n",
    "\n",
    "\n",
    "# Directory containing the images\n",
    "inDir_Crop = mainDir + \"/OriFrames\"\n",
    "outDir_Crop = mainDir + \"/CroppedRect\"\n",
    "\n",
    "if not os.path.exists(outDir_Crop):\n",
    "    os.makedirs(outDir_Crop)\n",
    "\n",
    "# Get a list of image file names in the directory\n",
    "image_files = [f for f in os.listdir(inDir_Crop) if f.endswith('.png')]\n",
    "\n",
    "# Load the images\n",
    "images = [cv2.imread(os.path.join(inDir_Crop, image_file)) for image_file in image_files]\n",
    "\n",
    "# Draw a box on the first image\n",
    "box_start, box_end = draw_box(images[0])\n",
    "\n",
    "# Crop the series of images\n",
    "cropped_images = crop_images(images, box_start, box_end)\n",
    "\n",
    "def returnZero(currentI, desiredNum):\n",
    "    ans = \"\"\n",
    "    for i in range(desiredNum - len(str(currentI))):\n",
    "        ans += \"0\"\n",
    "    return ans\n",
    "\n",
    "# Save the cropped images\n",
    "for i, cropped_image in enumerate(cropped_images):\n",
    "    cv2.imwrite(os.path.join(outDir_Crop, returnZero(i + 1, len(str(len(cropped_images)))) + f\"{i + 1}.png\"), cropped_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Image Crop in polygon\n",
    "\n",
    "WINDOW_WIDTH, WINDOW_HEIGHT = 800, 600  # Define the fixed size for the editing window\n",
    "points = []  # To store the points drawn on the first image\n",
    "input_directory = mainDir + \"/CroppedRect\"\n",
    "output_directory = mainDir+\"/Cropped\"\n",
    "\n",
    "def crop_image(image, points, resize_factor):\n",
    "    mask = np.zeros(image.shape[:2], dtype=np.uint8)\n",
    "    points_np = np.array(points, dtype=np.int32)  # Convert points to a numpy array\n",
    "    points_resized = (points_np * resize_factor).astype(np.int32)\n",
    "    cv2.drawContours(mask, [points_resized], -1, 255, thickness=cv2.FILLED)\n",
    "\n",
    "    # Crop the face region from the original image\n",
    "    face = cv2.bitwise_and(image, image, mask=mask)\n",
    "\n",
    "    # Create a new image with an alpha channel (4 channels)\n",
    "    h, w = face.shape[:2]\n",
    "    cropped_with_alpha = np.zeros((h, w, 4), dtype=np.uint8)\n",
    "    cropped_with_alpha[:, :, :3] = face\n",
    "    cropped_with_alpha[:, :, 3] = mask\n",
    "\n",
    "    return cropped_with_alpha\n",
    "\n",
    "def draw_outline(event, x, y, flags, param):\n",
    "    if event == cv2.EVENT_LBUTTONDOWN:\n",
    "        points.append((x, y))\n",
    "    elif event == cv2.EVENT_LBUTTONUP:\n",
    "        cv2.circle(clone, (x, y), 2, (0, 0, 255), -1)\n",
    "        if len(points) > 1:\n",
    "            cv2.polylines(clone, np.array([points]), True, (0, 0, 255), 1)\n",
    "        cv2.imshow(\"Image\", clone)\n",
    "\n",
    "def main():\n",
    "    os.makedirs(output_directory, exist_ok=True)\n",
    "\n",
    "    first_image = None\n",
    "\n",
    "    for filename in os.listdir(input_directory):\n",
    "        if filename.endswith(\".png\") or filename.endswith(\".jpg\") or filename.endswith(\".jpeg\"):\n",
    "            image_path = os.path.join(input_directory, filename)\n",
    "            image = cv2.imread(image_path)\n",
    "\n",
    "            if image is not None:\n",
    "                if first_image is None:\n",
    "                    first_image = image.copy()\n",
    "\n",
    "                    global clone\n",
    "                    clone = first_image.copy()\n",
    "\n",
    "                    # Resize the image and clone to the fixed window size\n",
    "                    height, width = clone.shape[:2]\n",
    "                    resize_factor = min(WINDOW_WIDTH / width, WINDOW_HEIGHT / height)\n",
    "                    clone = cv2.resize(clone, None, fx=resize_factor, fy=resize_factor)\n",
    "\n",
    "                    cv2.namedWindow(\"Image\", cv2.WINDOW_NORMAL)  # Allow window resizing\n",
    "                    cv2.resizeWindow(\"Image\", clone.shape[1], clone.shape[0])\n",
    "\n",
    "                    cv2.setMouseCallback(\"Image\", draw_outline)\n",
    "\n",
    "                    print(\"Draw an outline on the image and press 'c' to crop or 'ESC' to skip.\")\n",
    "\n",
    "                    while True:\n",
    "                        cv2.imshow(\"Image\", clone)\n",
    "                        key = cv2.waitKey(1) & 0xFF\n",
    "                        if key == ord(\"r\"):  # Press 'r' to reset the points\n",
    "                            clone = cv2.resize(first_image.copy(), None, fx=resize_factor, fy=resize_factor)\n",
    "                            points.clear()\n",
    "                        elif key == ord(\"c\"):  # Press 'c' to continue\n",
    "                            if len(points) > 2:\n",
    "                                cv2.destroyAllWindows()\n",
    "                                break\n",
    "                        elif key == 27:  # Press 'ESC' to skip\n",
    "                            cv2.destroyAllWindows()\n",
    "                            first_image = None\n",
    "                            break\n",
    "\n",
    "                if len(points) > 2:\n",
    "                    cropped_image = crop_image(image, points, 1/resize_factor)\n",
    "                    output_path = os.path.join(output_directory, filename)\n",
    "                    cv2.imwrite(output_path, cropped_image)\n",
    "                    print(f\"{filename} cropped and saved successfully!\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Eye Blacks\n",
    "import dlib\n",
    "def detect_eyes(image_path: str):\n",
    "    \"\"\"\n",
    "    Detect eyes in the provided image using Dlib's facial landmarks detector.\n",
    "\n",
    "    Parameters:\n",
    "    - image_path (str): Path to the input image.\n",
    "\n",
    "    Returns:\n",
    "    - Tuple of left_eye and right_eye coordinates to be blacked out.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load the image using OpenCV\n",
    "    image = cv2.imread(image_path)\n",
    "\n",
    "    # Convert the image to grayscale\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "    # Initialize Dlib's face detector and facial landmarks predictor\n",
    "    detector = dlib.get_frontal_face_detector()\n",
    "    predictor = dlib.shape_predictor(r\"C:\\Users\\ahj28\\Desktop\\Python\\shape_predictor_68_face_landmarks.dat\")  #CHANGE FILE PATH\n",
    "\n",
    "    # Detect faces in the image\n",
    "    faces = detector(gray)\n",
    "\n",
    "    if len(faces) > 0:\n",
    "        # Take the first detected face\n",
    "        face = faces[0]\n",
    "\n",
    "        # Predict facial landmarks\n",
    "        landmarks = predictor(gray, face)\n",
    "\n",
    "        # Use landmark points 36-41 for left eye and 42-47 for right eye, then adjust them\n",
    "        left_eye = adjust_landmarks(np.array([(landmarks.part(n).x, landmarks.part(n).y) for n in range(36, 42)]))\n",
    "        right_eye = adjust_landmarks(np.array([(landmarks.part(n).x, landmarks.part(n).y) for n in range(42, 48)]))\n",
    "\n",
    "        return left_eye, right_eye\n",
    "\n",
    "    # If no faces are detected, return None\n",
    "    return None, None\n",
    "\n",
    "def adjust_landmarks(landmarks, Vfactor=2.0, Hfactor = 1.2): #Tune (vertical & horizontal)\n",
    "    # Compute the centroid\n",
    "    centroid = np.mean(landmarks, axis=0)\n",
    "\n",
    "    # Adjust each landmark\n",
    "    adjusted = []\n",
    "    for i,point in enumerate(landmarks):\n",
    "        if i != 0 and i != 3:\n",
    "            extended_vector = point + (point - centroid) * Vfactor\n",
    "        else:\n",
    "            extended_vector = point + (point - centroid) * Hfactor\n",
    "        adjusted.append(tuple(extended_vector.astype(np.int32)))\n",
    "    return np.array(adjusted, dtype=np.int32)\n",
    "\n",
    "# Folder paths\n",
    "input_folder = mainDir + \"/Cropped\"\n",
    "output_folder = mainDir + \"/EyeBlack\"\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "\n",
    "# Process the first image to detect the region to be blacked out\n",
    "first_image_path = os.path.join(input_folder, os.listdir(input_folder)[0])\n",
    "left_eye_coords, right_eye_coords = detect_eyes(first_image_path)\n",
    "print(left_eye_coords)\n",
    "print(right_eye_coords)\n",
    "if left_eye_coords is not None and right_eye_coords is not None:\n",
    "    # Loop through the rest of the images and apply the same blacking out coordinates\n",
    "    for filename in os.listdir(input_folder):\n",
    "        if filename.endswith(\".jpg\") or filename.endswith(\".png\"):\n",
    "            input_image_path = os.path.join(input_folder, filename)\n",
    "            output_image_path = os.path.join(output_folder, filename)\n",
    "\n",
    "            # Load the image using OpenCV, including the alpha channel if it exists\n",
    "            image_with_alpha = cv2.imread(input_image_path, cv2.IMREAD_UNCHANGED)\n",
    "\n",
    "            # Check if the image has an alpha channel (transparency)\n",
    "            if image_with_alpha.shape[-1] == 4:\n",
    "                # Create a blank alpha channel with the same size as the image, set to fully opaque (255)\n",
    "                alpha_channel = np.ones((image_with_alpha.shape[0], image_with_alpha.shape[1]), dtype=np.uint8) * 255\n",
    "                # Preserve the original alpha channel for non-eye regions\n",
    "                alpha_channel[...] = image_with_alpha[:, :, 3]\n",
    "            else:\n",
    "                # Create a blank alpha channel if the image doesn't have transparency\n",
    "                alpha_channel = np.ones((image_with_alpha.shape[0], image_with_alpha.shape[1]), dtype=np.uint8) * 255\n",
    "\n",
    "            # Fill the polygons over the eyes contours with 0 (fully transparent) to make them transparent\n",
    "            cv2.fillPoly(alpha_channel, [left_eye_coords], color=0)\n",
    "            cv2.fillPoly(alpha_channel, [right_eye_coords], color=0)\n",
    "\n",
    "            # Merge the RGB channels with the updated alpha channel to create the new BGRA image\n",
    "            image_with_alpha = cv2.cvtColor(image_with_alpha, cv2.COLOR_BGR2BGRA)\n",
    "            image_with_alpha[:, :, 3] = alpha_channel\n",
    "\n",
    "            # Save the modified image with transparent eyes\n",
    "            cv2.imwrite(output_image_path, image_with_alpha)\n",
    "\n",
    "else: \n",
    "    print(\"HELLO NO EYES?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DISC Main\n",
    "# ====== IMPORTING MODULES\n",
    "# locate the pydic module\n",
    "#CHANGE THIS MODULEEE\n",
    "pydic = imp.load_source('pydic', r'C:\\Users\\ahj28\\Desktop\\Python\\plottingWithWeight.py') #CHANGE FILE PATH\n",
    "\n",
    "#  ====== RUN PYDIC TO COMPUTE DISPLACEMENT AND STRAIN FIELDS (STRUCTURED GRID)\n",
    "correl_wind_size = (80,80) # was (80,80) the size in pixel of the correlation windows\n",
    "correl_grid_size = (30,30) # was (50,50) the size in pixel of the interval (dx,dy) of the correlation grid\n",
    "\n",
    "pp = mainDir + \"/EyeBlack\"\n",
    "\n",
    "for filename in glob.glob(pp+'/*.png'):\n",
    "    print(filename)\n",
    "    sample_image_file=Image.open(filename)\n",
    "    break;\n",
    "\n",
    "dic_file = pp +'/result.dic'   # format: \"xxx.dic\"\n",
    "\n",
    "# read image series and write a separated result file\n",
    "#Tune (area of interest)\n",
    "pydic.init(pp+'/*.png', correl_wind_size, correl_grid_size, dic_file, area_of_intersest=[(0,0), (sample_image_file.width,sample_image_file.height)] , Ref_First = True)\n",
    "#can do all, if the area of interest is not there, \"all, none\" and can create new\n",
    "#def init(image_pattern, win_size_px, grid_size_px, result_file, area_of_intersest=None, Ref_First = False, *args, **kwargs)\n",
    "#cv2.waitKey(0)\n",
    "#cv2.destroyAllWindows()\n",
    "# and read the result file for computing strain and displacement field from the result file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Main DISC - 2\n",
    "pydic.FixedscaleValues = [30,30,0]\n",
    "#30 top range of movement and detection\n",
    "#Tune (Fixed Scale Vaules)\n",
    "pydic.read_dic_file(dic_file, FixedScale = False, interpolation='raw', save_image=True, scale_disp=1, scale_grid=1)\n",
    "#Fixed Scale is about backgroud. When True"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
